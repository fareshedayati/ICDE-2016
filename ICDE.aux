\relax 
\citation{freund1995desicion}
\citation{breiman2001random}
\citation{friedman2001greedy}
\citation{buitinck2013api}
\citation{pedregosa2011scikit}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Decision Trees With Dense Input Data}{1}}
\newlabel{sec:background}{{II}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Notation}{1}}
\newlabel{gini}{{1}{1}}
\citation{breiman1984classification}
\newlabel{entropy}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Training}{2}}
\newlabel{red}{{3}{2}}
\newlabel{left}{{4}{2}}
\newlabel{right}{{5}{2}}
\newlabel{tree_induction}{{1}{2}}
\newlabel{line_partition}{{12}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}The Optimal Split}{2}}
\newlabel{find_best_split}{{2}{2}}
\newlabel{alg-line:value-extract}{{4}{2}}
\newlabel{line_sorting}{{5}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Decision Trees With Sparse Input Data}{2}}
\newlabel{sec:sparse-input-dt}{{III}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Sparse matrix format}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Nonzero Values of $\mathcal  {L}_p$}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The array $mapping$ allows to efficiently compute the intersection between the $indices$ array of the csc matrix and a sample set $\mathcal  {L}_p$}}{4}}
\newlabel{fig:mapping}{{1}{4}}
\newlabel{switch}{{8}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}The Optimal Split}{4}}
\newlabel{algo:sparse-split}{{3}{4}}
\citation{joachims1996probabilistic}
\citation{bay2000archive}
\newlabel{map}{{4}{5}}
\newlabel{bsearch}{{5}{5}}
\newlabel{aux}{{6}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments}{5}}
\newlabel{sec:experiments}{{IV}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Density}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Real Data}{5}}
\citation{Bache+Lichman:2013}
\citation{Bache+Lichman:2013}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Leveraging the input sparsity significantly speed up decisions tree induction both with shallow and deep trees on the \emph  {20 Newsgroups} dataset. Note that the dataset is very sparse (density = 0.001).}}{6}}
\newlabel{fig:20news}{{2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Leveraging the input sparsity significantly speed up decisions tree induction both with shallow and deep trees on the \emph  {cup} dataset. Note that the dataset is quite sparse (density = 0.014).}}{6}}
\newlabel{fig:cup}{{3}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Leveraging the input sparsity does not speed up training of deep trees on the \emph  {adult} dataset. Note that the dataset is quite dense (density = 0.11).}}{6}}
\newlabel{fig:adult}{{4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Leveraging the input sparsity does not speed up training trees on the \emph  {tic} dataset. Note that the dataset is very dense (density = 0.44).}}{6}}
\newlabel{fig:tic}{{5}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Synthetic Data}{6}}
\citation{hastie:book2008}
\citation{breiman1984classification}
\citation{Quinlan:1993:CPM:152181}
\citation{Schapire99improvedboosting}
\citation{das:blog2014}
\citation{Zaharia:2010:SCC:1863103.1863113}
\citation{Chang:2011:LLS:1961189.1961199}
\citation{buitinck2013api}
\bibstyle{abbrv}
\bibdata{references}
\bibcite{Bache+Lichman:2013}{1}
\bibcite{bay2000archive}{2}
\bibcite{breiman2001random}{3}
\bibcite{breiman1984classification}{4}
\bibcite{buitinck2013api}{5}
\bibcite{Chang:2011:LLS:1961189.1961199}{6}
\bibcite{das:blog2014}{7}
\bibcite{freund1995desicion}{8}
\bibcite{friedman2001greedy}{9}
\bibcite{hastie:book2008}{10}
\bibcite{joachims1996probabilistic}{11}
\bibcite{pedregosa2011scikit}{12}
\bibcite{Quinlan:1993:CPM:152181}{13}
\bibcite{Schapire99improvedboosting}{14}
\bibcite{Zaharia:2010:SCC:1863103.1863113}{15}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Significant speed up is achieved by the sparsity-aware decision tree algorithm whenever the density is below 0.2 (or sparsity over 0.8).}}{7}}
\newlabel{fig:density}{{6}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Related Work}{7}}
\newlabel{sec:related}{{V}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{7}}
\newlabel{sec:conclusion}{{VI}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Acknowledgment}{7}}
\@writefile{toc}{\contentsline {section}{References}{7}}
